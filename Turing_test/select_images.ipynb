{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Turing test image selection\n",
    "\n",
    "This notebook will help randomly select images from dataset, crop and normalize the images and reconstruct images to form the Turing test dataset\n",
    "\n",
    "## Helper functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cf919fec17098f5"
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import dnnlib\n",
    "import legacy\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "def resize_crop(img_dir, resize_by=1., resolution=512, brightness_norm=True, brightness_mean=107.2, locations=None):\n",
    "    if locations is None:\n",
    "        locations = [\"left\", \"right\"]\n",
    "    img = cv2.imread(img_dir, cv2.IMREAD_UNCHANGED)\n",
    "    if img.dtype != np.uint8:\n",
    "        img = np.uint8(img / 256)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_shape = img.shape\n",
    "    resize_shape = np.array([img_shape[1] * resize_by, img_shape[0] * resize_by], dtype=int)\n",
    "    if resize_by != 1:\n",
    "        img = cv2.resize(img, resize_shape, cv2.INTER_LANCZOS4)\n",
    "    imgs = []\n",
    "    for location in locations:\n",
    "        if location == \"left\":\n",
    "            new_img = img[(resize_shape[1] - resolution) // 2:(resize_shape[1] + resolution) // 2, :resolution]\n",
    "        elif location == \"right\":\n",
    "            new_img = img[(resize_shape[1] - resolution) // 2:(resize_shape[1] + resolution) // 2, -resolution:]\n",
    "        else:\n",
    "            new_img = img[(resize_shape[1] - resolution) // 2:(resize_shape[1] + resolution) // 2,\n",
    "                      (resize_shape[0] - resolution) // 2:(resize_shape[0] + resolution) // 2]\n",
    "        if brightness_norm:\n",
    "            obj_v = np.mean(new_img)\n",
    "            value = brightness_mean - obj_v\n",
    "            new_img = cv2.add(new_img, value)\n",
    "        imgs.append(new_img)\n",
    "    return imgs\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T00:08:11.365402Z",
     "start_time": "2024-03-23T00:08:11.354082Z"
    }
   },
   "id": "396e1f37fe9e0134",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Randomly select images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3636c0167696d497"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T00:08:28.689971Z",
     "start_time": "2024-03-23T00:08:17.550232Z"
    }
   },
   "source": [
    "ROOT_DIR = \"/home/xavier/Documents/dataset/Welch/trainingset2/trainingset2\"\n",
    "LABEL_DIR = \"/home/xavier/Documents/dataset/Welch/trainingset2/InceptionV3-labels.pkl\"\n",
    "samples = 30\n",
    "# timepoint_pool = [60] * 1 + [600] * 2 + [960] * 3 + [1440] * 4\n",
    "\n",
    "label_dict = pkl.load(open(LABEL_DIR, 'rb'))\n",
    "\n",
    "class_run_scope_idx = []\n",
    "for class_label in label_dict:\n",
    "    for file_string in label_dict[class_label]:\n",
    "        strain = file_string.split('/')[0]\n",
    "        scope_pattern = r\"Scope(\\d{2})/\"\n",
    "        scope_match = int(re.search(scope_pattern, file_string).group(1))\n",
    "        index_pattern = r\"_(\\d{4}).jpg\"\n",
    "        index_match = int(re.search(index_pattern, file_string).group(1))\n",
    "        class_run_scope_idx.append((class_label, strain, scope_match, index_match))\n",
    "class_run_scope_idx = pd.DataFrame(class_run_scope_idx, columns=[\"Class\", \"Strain\", \"Scope\", \"Index\"])\n",
    "\n",
    "annotations = []\n",
    "for strain in os.listdir(ROOT_DIR):\n",
    "    scopes = [int(folder[-2:]) for folder in os.listdir(os.path.join(ROOT_DIR, strain))]\n",
    "    pattern = r\"(_scope)(\\d{1,2})(-00_)(\\d{4})(\\.jpg)\"\n",
    "    img_name = re.sub(pattern, r\"\\g<1>\" + \"%d\" + r\"\\3\" + \"%04d\" + r\"\\5\",\n",
    "                      os.listdir(os.path.join(ROOT_DIR, strain, f\"Scope{scopes[0]:02d}\"))[0])\n",
    "    scopes += [None] * (3 - len(scopes))\n",
    "    annotations.append([strain] + scopes + [img_name])\n",
    "\n",
    "df = pd.DataFrame(annotations, columns=['Strain', 'Scope1', 'Scope2', 'Scope3', \"Name\"])\n",
    "# Convert 'Scope' columns to nullable integer type\n",
    "df['Scope1'] = df['Scope1'].astype('Int64')\n",
    "df['Scope2'] = df['Scope2'].astype('Int64')\n",
    "df['Scope3'] = df['Scope3'].astype('Int64')\n",
    "\n",
    "filtered_df = df.dropna(subset=['Scope2'])\n",
    "\n",
    "# Filter strains with at least 2 scopes.\n",
    "class_run_scope_idx = class_run_scope_idx[class_run_scope_idx['Strain'].isin(filtered_df['Strain'])]\n",
    "\n",
    "final_directory_pairs = []\n",
    "class_label = 0\n",
    "selected_strains = set()\n",
    "while len(final_directory_pairs) < samples:\n",
    "    # Filter class_run_scope_idx to include only the current class with available strains\n",
    "    current_class_samples = class_run_scope_idx[class_run_scope_idx[\"Class\"] == class_label]\n",
    "\n",
    "    if not current_class_samples.empty:\n",
    "        # Randomly select a sample from the current class\n",
    "        sample_row = current_class_samples.sample(n=1).iloc[0]\n",
    "        strain, scope1, index = sample_row[\"Strain\"], sample_row[\"Scope\"], sample_row[\"Index\"]\n",
    "\n",
    "        # Get the experimental replicate information\n",
    "        run_info = df[df[\"Strain\"] == strain].iloc[0]\n",
    "        valid_scopes = [option for option in [run_info[\"Scope1\"], run_info[\"Scope2\"], run_info[\"Scope3\"]] if\n",
    "                        not pd.isna(option) and option != scope1]\n",
    "\n",
    "        if valid_scopes:\n",
    "            scope2 = random.choice(valid_scopes)\n",
    "            file1 = f\"{ROOT_DIR}/{strain}/Scope{scope1:02d}/{run_info['Name'] % (scope1, index)}\"\n",
    "            file2 = f\"{ROOT_DIR}/{strain}/Scope{scope2:02d}/{run_info['Name'] % (scope2, index)}\"\n",
    "            # print(file1, file2)\n",
    "            if not os.path.exists(file1) or not os.path.exists(file2):\n",
    "                print(file1, file2)\n",
    "            #     index -= 1\n",
    "            #     file1 = f\"{ROOT_DIR}/{strain}/Scope{scope1:02d}/{run_info['Name'] % (scope1, index)}\"\n",
    "            #     file2 = f\"{ROOT_DIR}/{strain}/Scope{scope2:02d}/{run_info['Name'] % (scope2, index)}\"\n",
    "            final_directory_pairs.append([file1, file2])\n",
    "            if strain in selected_strains:\n",
    "                print(strain)\n",
    "            selected_strains.add(strain)\n",
    "            # Remove the selected strain from all classes\n",
    "            class_run_scope_idx = class_run_scope_idx[class_run_scope_idx[\"Strain\"] != strain]\n",
    "\n",
    "    # Move to the next class in a round-robin fashion\n",
    "    class_label = (class_label + 1) % 13\n",
    "    if class_run_scope_idx.empty:\n",
    "        break  # Exit if there are no more eligible strains across all classes"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# For alignment test\n",
    "## Get images and reconstructions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f43bc19497d80cd9"
  },
  {
   "cell_type": "code",
   "source": [
    "OUT_DIR = \"/home/xavier/PycharmProjects/TuringTest/fidelity\"\n",
    "\n",
    "os.environ['CC'] = \"/usr/bin/gcc-9\"\n",
    "os.environ['CXX'] = \"/usr/bin/g++-9\"\n",
    "device = torch.device('cuda')\n",
    "model_dict = {\n",
    "    # 7: \"/home/xavier/PycharmProjects/training-runs/new/e7/00001-stylegan2-trainingset2-gpus4-batch96-gamma10/network-snapshot-001461.pkl\",\n",
    "    # 10: \"/home/xavier/PycharmProjects/training-runs/new/e10/00001-stylegan2-trainingset2-gpus4-batch96-gamma10/network-snapshot-001411.pkl\",\n",
    "    # 12: \"/home/xavier/PycharmProjects/training-runs/new/e12/00008-stylegan2-trainingset2-gpus4-batch96-gamma10/network-snapshot-001461.pkl\",\n",
    "    13: \"/home/xavier/PycharmProjects/training-runs/new/e13/00008-stylegan2-trainingset2-gpus4-batch96-gamma10/network-snapshot-001461.pkl\",\n",
    "    # 14: \"/home/xavier/PycharmProjects/training-runs/new/e14/00010-stylegan2-trainingset2-gpus4-batch96-gamma10/network-snapshot-001461.pkl\",\n",
    "    # 18: \"/home/xavier/PycharmProjects/training-runs/new/e18/00001-stylegan2-trainingset2-gpus4-batch96-gamma10/network-snapshot-001461.pkl\",\n",
    "}\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_image(image, container, filename):\n",
    "    path = os.path.join(OUT_DIR, container)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    cv2.imwrite(os.path.join(path, filename), image)\n",
    "\n",
    "\n",
    "imgs_orig = []\n",
    "imgs_other = []\n",
    "imgs_rep = []\n",
    "for i, (scope1, scope2) in enumerate(final_directory_pairs):\n",
    "    left_crop, right_crop = resize_crop(scope1)\n",
    "    center_crop = resize_crop(scope2, locations=['center'])[0]\n",
    "    save_image(left_crop, 'crops_l', os.path.basename(scope1))\n",
    "    save_image(right_crop, 'crops_r', os.path.basename(scope1))\n",
    "    save_image(center_crop, 'crops_cp', os.path.basename(scope2))\n",
    "    imgs_orig.append(left_crop[np.newaxis, np.newaxis, :, :])\n",
    "    imgs_other.append(right_crop[np.newaxis, np.newaxis, :, :])\n",
    "    imgs_rep.append(center_crop[np.newaxis, np.newaxis, :, :])\n",
    "\n",
    "loss_all = {}\n",
    "# Now calculate and add the similarities for each model's reconstructions\n",
    "for model_e, model_path in model_dict.items():\n",
    "    with dnnlib.util.open_url(model_path) as fp:\n",
    "        models = legacy.load_network_pkl(fp)\n",
    "    E, G = models['E_ema'].to(device), models['G_ema'].to(device)\n",
    "\n",
    "    loss_all[model_e] = 0\n",
    "    similarities = []\n",
    "    for img_l, (img_name, _) in zip(imgs_orig, final_directory_pairs):\n",
    "        img_l_tensor = torch.tensor(img_l, device=device, dtype=torch.float32).div(127.5).sub(1)\n",
    "        mu, logvar = E.mu_var(img_l_tensor, None)\n",
    "        recon = G(mu, None).detach()\n",
    "        recon_clipped = torch.clip(recon, -1, 1)\n",
    "        recon_rescaled = recon_clipped.add(1).div(2).mul(255).type(torch.uint8)\n",
    "        recon_output = recon_rescaled.detach().cpu().numpy()[0, 0]\n",
    "        subdir = f'dim_{model_e}_reconstructions'\n",
    "        save_image(recon_output, subdir, os.path.basename(img_name))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T00:09:11.267037Z",
     "start_time": "2024-03-23T00:09:10.780264Z"
    }
   },
   "id": "6a8190f0e4c9a62b",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the next step, use project_all.sh in stylegan2-ada-pytorch to get the other reconstruction."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5c40b1c6c3805b4"
  },
  {
   "cell_type": "code",
   "source": [
    "PROJECT_DIR = \"/home/xavier/PycharmProjects/TuringTest/new/crops_bp\"\n",
    "COLLECT_DIR = \"/home/xavier/PycharmProjects/TuringTest/new/crops_stylegan2\"\n",
    "os.makedirs(COLLECT_DIR, exist_ok=True)\n",
    "import shutil\n",
    "\n",
    "for folder in os.listdir(PROJECT_DIR):\n",
    "    shutil.copy(os.path.join(PROJECT_DIR, folder, \"proj.png\"), os.path.join(COLLECT_DIR, f\"{folder}.png\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T00:58:41.376116Z",
     "start_time": "2024-03-20T00:58:41.291008Z"
    }
   },
   "id": "3c433a04fc7e19d9",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert image labels to embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ff9713a6feaf1ce"
  },
  {
   "cell_type": "code",
   "source": [
    "# File path to your .xlsx file\n",
    "file_path = '/home/xavier/PycharmProjects/TuringTest/new/Qualtrics_labels.xlsx'\n",
    "\n",
    "# Open the Excel file\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Initialize a list to hold data from each sheet\n",
    "sheets_data = []\n",
    "\n",
    "# Iterate over each sheet in the Excel file\n",
    "for sheet_name in xls.sheet_names:\n",
    "    # Read the current sheet\n",
    "    sheet_data = pd.read_excel(xls, sheet_name)\n",
    "\n",
    "    # Assuming the image column is named 'Image' and label column is 'Label'\n",
    "    # Adjust column names as per your file\n",
    "    image_column = sheet_data['Image']\n",
    "    label_column = sheet_data['Label']\n",
    "\n",
    "    # Transform the label column to the desired format\n",
    "    transformed_label = label_column.apply(lambda\n",
    "                                               x: f'<img src=\"https://riceuniversity.co1.qualtrics.com/ControlPanel/Graphic.php?IM={x}\" style=\"width:256px;height:256px;\"/>')\n",
    "\n",
    "    # If it's the first sheet, keep the image column; else, only keep the transformed label\n",
    "    if sheet_name == xls.sheet_names[0]:\n",
    "        sheets_data.append(pd.DataFrame({\n",
    "            'Image': image_column,\n",
    "            f'Label_{sheet_name}': transformed_label\n",
    "        }))\n",
    "    else:\n",
    "        sheets_data.append(pd.DataFrame({\n",
    "            f'Label_{sheet_name}': transformed_label\n",
    "        }))\n",
    "\n",
    "# Concatenate all dataframes horizontally, assuming images are in the same order across sheets\n",
    "full_sheet_data = pd.concat(sheets_data, axis=1)\n",
    "\n",
    "# If there are duplicate 'Image' columns (from each sheet), drop them except the first occurrence\n",
    "full_sheet_data = full_sheet_data.loc[:, ~full_sheet_data.columns.duplicated()]\n",
    "\n",
    "full_sheet_data = full_sheet_data.sample(n=30)\n",
    "# Save the full sheet data to a new Excel file\n",
    "full_sheet_data.to_excel('/home/xavier/PycharmProjects/TuringTest/new/combined_labels30.xlsx', index=False)\n",
    "\n",
    "print('Conversion complete. The combined labels sheet has been saved as \"combined_labels.xlsx\".')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:24:53.279911Z",
     "start_time": "2024-03-22T03:24:53.221286Z"
    }
   },
   "id": "6308ed8ef15092b1",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get 30 samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90b3ef1478a80491"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2b7878b51134de1b",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
