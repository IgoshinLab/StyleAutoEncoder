{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "WORKING_DIR = \"/home/xavier/Documents/DAE_project\"",
   "id": "8369424d60a3be1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reconstruct images with different hyper parameters",
   "id": "a8f7e516819db57"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-24T21:35:47.754928Z",
     "start_time": "2025-08-24T21:35:40.887828Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "IMG_DIR = f\"{WORKING_DIR}/dataset/Roy_training/images\"\n",
    "container = []\n",
    "\n",
    "for strain in os.listdir(IMG_DIR):\n",
    "    run_id = int(strain.split(\"Run\")[1])\n",
    "    strain_path = os.path.join(IMG_DIR, strain)\n",
    "    for scope in os.listdir(strain_path):\n",
    "        scope_path = os.path.join(strain_path, scope)\n",
    "        container.append([run_id, int(scope[-2:]), scope_path])\n",
    "container = pd.DataFrame(container, columns=[\"Run\", \"Scope\", \"Directory\"])\n",
    "\n",
    "LABEL_DIR = f'{WORKING_DIR}/dataset/Roy_training/Caro 3d 9.7.22_2.20_new.xlsx'\n",
    "\n",
    "label_df = pd.read_excel(LABEL_DIR)\n",
    "\n",
    "annotated_container = pd.merge(container, label_df, on=\"Run\")\n",
    "\n",
    "OUT_DIR = f\"{WORKING_DIR}/images/sup_figure2\"\n",
    "selected_dir = os.path.join(OUT_DIR, \"targets\")\n",
    "os.makedirs(selected_dir, exist_ok=True)\n",
    "SELECTED_FRAMES = [1441]\n",
    "selected_strains = [1622, 8615, 2232, 4398, 4299, 5208, 4408]\n",
    "filtered_df = annotated_container[annotated_container[\"Mutant #\"].isin(selected_strains)]\n",
    "for _, row in filtered_df.iterrows():\n",
    "    images = os.listdir(row[\"Directory\"])\n",
    "    name_format = images[0][:-8] + \"%04d.jpg\"\n",
    "    for selected_frame in SELECTED_FRAMES:\n",
    "        try:\n",
    "            shutil.copy(os.path.join(row[\"Directory\"], name_format % selected_frame),\n",
    "                        os.path.join(selected_dir, f\"{row['Mutant #']}_\" + name_format % selected_frame))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{selected_frame} not found in {row['Directory']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1441 not found in D:/Projects/trainingset2\\CS2_44_1622_1%agar_Run0320\\Scope22\n",
      "1441 not found in D:/Projects/trainingset2\\CS2_44_1622_1%agar_Run0320\\Scope23\n",
      "1441 not found in D:/Projects/trainingset2\\CS2_44_1622_1%agar_Run0320\\Scope24\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T21:39:06.565242Z",
     "start_time": "2025-08-24T21:38:03.380900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper functions\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import dnnlib\n",
    "import legacy\n",
    "from multiprocessing import Pool\n",
    "import functools\n",
    "from training.networks_stylegan2 import SynthesisLayer, MinibatchStdLayer\n",
    "\n",
    "os.environ['CC'] = \"/usr/bin/gcc-9\"\n",
    "os.environ['CXX'] = \"/usr/bin/g++-9\"\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "def reset_noise_const(G, seed):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    for block in G.synthesis.children():\n",
    "        for layer in block.children():\n",
    "            if layer.__class__.__name__ == \"SynthesisLayer\":  #isinstance(layer, SynthesisLayer):\n",
    "                resolution = layer.resolution\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    layer.noise_const.copy_(torch.randn([resolution, resolution]))\n",
    "\n",
    "\n",
    "def resize_crop(img_name, resize_by=1., resolution=512, brightness_norm=True, brightness_mean=107):\n",
    "    img = cv2.imread(img_name, cv2.IMREAD_UNCHANGED)\n",
    "    if img.dtype != np.uint8:\n",
    "        img = np.uint8(img / 256)\n",
    "    img_shape = img.shape\n",
    "    resize_shape = np.array([img_shape[1] * resize_by, img_shape[0] * resize_by], dtype=int)\n",
    "    if resize_by != 1:\n",
    "        img = cv2.resize(img, resize_shape, cv2.INTER_LANCZOS4)\n",
    "    img = img[(resize_shape[1] - resolution) // 2:(resize_shape[1] + resolution) // 2,\n",
    "    (resize_shape[0] - resolution) // 2:(resize_shape[0] + resolution) // 2]\n",
    "    if brightness_norm:\n",
    "        obj_v = np.mean(img)\n",
    "        value = brightness_mean - obj_v\n",
    "        img = cv2.add(img, value)\n",
    "    return img\n",
    "\n",
    "\n",
    "target_images = []\n",
    "img_names = []\n",
    "target_folder = os.path.join(OUT_DIR, \"reconstructions/targets\")\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "for img_name in os.listdir(os.path.join(OUT_DIR, \"selected_targets\")):\n",
    "    target_image = resize_crop(os.path.join(OUT_DIR, \"selected_targets\", img_name))\n",
    "    target_images.append(target_image)\n",
    "    img_names.append(img_name)\n",
    "    cv2.imwrite(os.path.join(target_folder, img_name), target_image)\n",
    "\n",
    "# row1 = np.hstack(target_images[:4])  # First row\n",
    "# row2 = np.hstack(target_images[4:8])  # Second row\n",
    "# grid_image = np.vstack([row1, row2])  # Stack rows\n",
    "# cv2.imwrite(os.path.join(OUT_DIR, \"reconstructions_none\", f\"target.png\"), grid_image)\n",
    "target_images = np.array(target_images)\n",
    "target_images = torch.Tensor(target_images).to(device).to(torch.float32) / 127.5 - 1\n",
    "target_images = target_images[:, None, :, :]\n",
    "\n",
    "ROOT_DIR = f\"{WORKING_DIR}/models/others/\"\n",
    "model_dirs = {\n",
    "    \"e10-pre\": \"e10-pre/new/00000-stylegan2-pre-training-gpus4-batch112-gamma10\",\n",
    "    \"e11-pre\": \"e11-pre/00002-stylegan2-pre-training-gpus4-batch112-gamma10\",\n",
    "    \"e12-pre\": \"e12-pre/00001-stylegan2-pre-training-gpus4-batch112-gamma10\",\n",
    "    \"e13-pre\": \"e13-pre/00002-stylegan2-pre-training-gpus4-batch112-gamma10\",\n",
    "    \"e13\": \"e13/00001-stylegan2-trainingset2-gpus4-batch96-gamma10\",\n",
    "    \"e14-pre\": \"e14-pre/00001-stylegan2-pre-training-gpus4-batch112-gamma10\",\n",
    "    \"e15-pre\": \"e15-pre/00000-stylegan2-pre-training-gpus4-batch112-gamma10\"\n",
    "}\n",
    "\n",
    "for model_label in model_dirs:\n",
    "    model_dir = os.path.join(ROOT_DIR, model_dirs[model_label], \"network-snapshot-000252.pkl\")\n",
    "    reconstructed_dir = os.path.join(OUT_DIR, \"reconstructions_none\", model_label)\n",
    "    os.makedirs(reconstructed_dir, exist_ok=True)\n",
    "    with dnnlib.util.open_url(model_dir) as fp:\n",
    "        models = legacy.load_network_pkl(fp)\n",
    "        E = models['E_ema'].to(device)\n",
    "        E.b4.get_mu.mbstd = MinibatchStdLayer(4).eval()\n",
    "        E.b4.get_logvar.mbstd = MinibatchStdLayer(4).eval()\n",
    "        G = models['G_ema'].to(device)  # type: ignore\n",
    "\n",
    "    z, logvar = E.mu_var(target_images, None)\n",
    "    for random_seed in [6, 26]:\n",
    "        reset_noise_const(G, random_seed)\n",
    "        reconstructed_images = G(z, None, noise_mode='const')\n",
    "        reconstructed_images = (reconstructed_images + 1) * 127.5\n",
    "        reconstructed_images = reconstructed_images.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8).cpu().numpy()[:,\n",
    "        :, :,\n",
    "        0]\n",
    "        for reconstructed_image, img_name in zip(reconstructed_images, img_names):\n",
    "            cv2.imwrite(os.path.join(reconstructed_dir, f\"{random_seed - 6}_{img_name}\"), reconstructed_image)\n",
    "        # row1 = np.hstack(reconstructed_images[:4])  # First row\n",
    "        # row2 = np.hstack(reconstructed_images[4:8])  # Second row\n",
    "        # grid_image = np.vstack([row1, row2])  # Stack rows\n",
    "        # cv2.imwrite(os.path.join(OUT_DIR, \"reconstructions_none\", f\"{random_seed}_{model_label}.png\"), grid_image)"
   ],
   "id": "97881bcc0eddbb83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\.conda\\envs\\py3_9\\lib\\site-packages\\torch\\utils\\cpp_extension.py:446: UserWarning: Error checking compiler version for /usr/bin/g++-9: [WinError 2] The system cannot find the file specified\n",
      "  warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n",
      "C:\\Users\\zhang\\.conda\\envs\\py3_9\\lib\\site-packages\\torch\\utils\\cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T21:39:51.191001Z",
     "start_time": "2025-08-24T21:39:43.189657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dirs = {\n",
    "    \"e13-post\": \"e13-post/from302kimgs/00000-stylegan2-trainingset2-gpus4-batch112-gamma10\",\n",
    "    \"e13-scratch\": \"e13-scratch/00000-stylegan2-trainingset2-gpus4-batch112-gamma10\",\n",
    "}\n",
    "\n",
    "for model_label in model_dirs:\n",
    "    model_dir = os.path.join(ROOT_DIR, model_dirs[model_label], \"network-snapshot-001512.pkl\")\n",
    "    reconstructed_dir = os.path.join(OUT_DIR, \"reconstructions_none\", model_label)\n",
    "    os.makedirs(reconstructed_dir, exist_ok=True)\n",
    "    with dnnlib.util.open_url(model_dir) as fp:\n",
    "        models = legacy.load_network_pkl(fp)\n",
    "        E = models['E_ema'].to(device)\n",
    "        E.b4.get_mu.mbstd = MinibatchStdLayer(4).eval()\n",
    "        E.b4.get_logvar.mbstd = MinibatchStdLayer(4).eval()\n",
    "        G = models['G_ema'].to(device)  # type: ignore\n",
    "\n",
    "    z, logvar = E.mu_var(target_images, None)\n",
    "    for random_seed in [6, 26]:\n",
    "        reset_noise_const(G, random_seed)\n",
    "        reconstructed_images = G(z, None, noise_mode='const')\n",
    "        reconstructed_images = (reconstructed_images + 1) * 127.5\n",
    "        reconstructed_images = reconstructed_images.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8).cpu().numpy()[:,\n",
    "        :, :,\n",
    "        0]\n",
    "        for reconstructed_image, img_name in zip(reconstructed_images, img_names):\n",
    "            cv2.imwrite(os.path.join(reconstructed_dir, f\"{random_seed - 6}_{img_name}\"), reconstructed_image)\n",
    "        # row1 = np.hstack(reconstructed_images[:4])  # First row\n",
    "        # row2 = np.hstack(reconstructed_images[4:])  # Second row\n",
    "        # grid_image = np.vstack([row1, row2])  # Stack rows\n",
    "        # cv2.imwrite(os.path.join(OUT_DIR, \"reconstructions_none\", f\"{model_label}.png\"), grid_image)"
   ],
   "id": "f0af333527c2a712",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b93994c27f62f511"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
